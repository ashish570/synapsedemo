{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "synapsepgbdemo"
		},
		"synapsepgbdemo-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'synapsepgbdemo-WorkspaceDefaultSqlServer'"
		},
		"synapsepgbdemo-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://sapgbdemo1.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/sppgbdemo')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synapsepgbdemo-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('synapsepgbdemo-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synapsepgbdemo-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('synapsepgbdemo-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Boston house price prediction')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sppgbdemo",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7c53f361-2400-4e8e-8114-f2bede5b6f9e"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a354618a-57e3-4180-ae87-3fed27f4297d/resourceGroups/rgpgbdemo/providers/Microsoft.Synapse/workspaces/synapsepgbdemo/bigDataPools/sppgbdemo",
						"name": "sppgbdemo",
						"type": "Spark",
						"endpoint": "https://synapsepgbdemo.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sppgbdemo",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"# Boston house price prediction with Vowpal Wabbit, LightGBM and Spark MLlib\n",
							"\n",
							"This notebook shows how to build simple regression models by using \n",
							"[Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) and \n",
							"[LightGBM](https://github.com/microsoft/LightGBM) with MMLSpark.\n",
							" We also compare the results with \n",
							" [Spark MLlib Linear Regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression)."
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"import math\n",
							"from matplotlib.colors import ListedColormap, Normalize\n",
							"from matplotlib.cm import get_cmap\n",
							"import matplotlib.pyplot as plt\n",
							"from mmlspark.train import ComputeModelStatistics\n",
							"from mmlspark.vw import VowpalWabbitRegressor, VowpalWabbitFeaturizer\n",
							"from mmlspark.lightgbm import LightGBMRegressor\n",
							"import numpy as np\n",
							"import pandas as pd\n",
							"from pyspark.ml.feature import VectorAssembler\n",
							"from pyspark.ml.regression import LinearRegression\n",
							"from sklearn.datasets import load_boston"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"## Prepare Dataset\n",
							"We use [*Boston house price* dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) \n",
							". \n",
							"The data was collected in 1978 from Boston area and consists of 506 entries with 14 features including the value of homes. \n",
							"We use `sklearn.datasets` module to download it easily, then split the set into training and testing by 75/25."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"boston = load_boston()\n",
							"\n",
							"feature_cols = ['f' + str(i) for i in range(boston.data.shape[1])]\n",
							"header = ['target'] + feature_cols\n",
							"df = spark.createDataFrame(\n",
							"    pd.DataFrame(data=np.column_stack((boston.target, boston.data)), columns=header)\n",
							").repartition(1)\n",
							"print(\"Dataframe has {} rows\".format(df.count()))\n",
							"display(df.limit(10).toPandas())"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"train_data, test_data = df.randomSplit([0.75, 0.25], seed=42)\n",
							"train_data.cache()\n",
							"test_data.cache()"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"Following is the summary of the training set."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"display(train_data.summary().toPandas())"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"Plot feature distributions over different target values (house prices in our case)."
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"features = train_data.columns[1:]\n",
							"values = train_data.drop('target').toPandas()\n",
							"ncols = 5\n",
							"nrows = math.ceil(len(features) / ncols)\n",
							"\n",
							"yy = [r['target'] for r in train_data.select('target').collect()]\n",
							"\n",
							"f, axes = plt.subplots(nrows, ncols, sharey=True, figsize=(30,10))\n",
							"f.tight_layout()\n",
							"\n",
							"for irow in range(nrows):\n",
							"    axes[irow][0].set_ylabel('target')\n",
							"    for icol in range(ncols):\n",
							"        try:\n",
							"            feat = features[irow*ncols + icol]\n",
							"            xx = values[feat]\n",
							"\n",
							"            axes[irow][icol].scatter(xx, yy, s=10, alpha=0.25)\n",
							"            axes[irow][icol].set_xlabel(feat)\n",
							"            axes[irow][icol].get_yaxis().set_ticks([])\n",
							"        except IndexError:\n",
							"            f.delaxes(axes[irow][icol])"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"## Baseline - Spark MLlib Linear Regressor\n",
							"\n",
							"First, we set a baseline performance by using Linear Regressor in Spark MLlib."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"featurizer = VectorAssembler(\n",
							"    inputCols=feature_cols,\n",
							"    outputCol='features'\n",
							")\n",
							"lr_train_data = featurizer.transform(train_data)['target', 'features']\n",
							"lr_test_data = featurizer.transform(test_data)['target', 'features']\n",
							"display(lr_train_data.limit(10).toPandas())"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"# By default, `maxIter` is 100. Other params you may want to change include: `regParam`, `elasticNetParam`, etc.\n",
							"lr = LinearRegression(\n",
							"    labelCol='target',\n",
							")\n",
							"\n",
							"lr_model = lr.fit(lr_train_data)\n",
							"lr_predictions = lr_model.transform(lr_test_data)\n",
							"\n",
							"display(lr_predictions.limit(10).toPandas())"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"We evaluate the prediction result by using `mmlspark.train.ComputeModelStatistics` which returns four metrics:\n",
							"* [MSE (Mean Squared Error)](https://en.wikipedia.org/wiki/Mean_squared_error)\n",
							"* [RMSE (Root Mean Squared Error)](https://en.wikipedia.org/wiki/Root-mean-square_deviation) = sqrt(MSE)\n",
							"* [R quared](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
							"* [MAE (Mean Absolute Error)](https://en.wikipedia.org/wiki/Mean_absolute_error)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"metrics = ComputeModelStatistics(\n",
							"    evaluationMetric='regression',\n",
							"    labelCol='target',\n",
							"    scoresCol='prediction'\n",
							").transform(lr_predictions)\n",
							"\n",
							"results = metrics.toPandas()\n",
							"results.insert(0, 'model', ['Spark MLlib - Linear Regression'])\n",
							"display(results)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"## Vowpal Wabbit"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"Perform VW-style feature hashing. Many types (numbers, string, bool, map of string to (number, string)) are supported."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"vw_featurizer = VowpalWabbitFeaturizer(\n",
							"    inputCols=feature_cols,\n",
							"    outputCol='features',\n",
							")\n",
							"vw_train_data = vw_featurizer.transform(train_data)['target', 'features']\n",
							"vw_test_data = vw_featurizer.transform(test_data)['target', 'features']\n",
							"display(vw_train_data.limit(10).toPandas())"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"See [VW wiki](https://github.com/vowpalWabbit/vowpal_wabbit/wiki/Command-Line-Arguments) for command line arguments."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"# Use the same number of iterations as Spark MLlib's Linear Regression (=100)\n",
							"args = \"--holdout_off --loss_function quantile -l 7 -q :: --power_t 0.3\"\n",
							"vwr = VowpalWabbitRegressor(\n",
							"    labelCol='target',\n",
							"    args=args,\n",
							"    numPasses=100,\n",
							")\n",
							"\n",
							"# To reduce number of partitions (which will effect performance), use `vw_train_data.repartition(1)`\n",
							"vw_train_data_2 = vw_train_data.repartition(1).cache()\n",
							"print(vw_train_data_2.count())\n",
							"vw_model = vwr.fit(vw_train_data_2.repartition(1))\n",
							"vw_predictions = vw_model.transform(vw_test_data)\n",
							"\n",
							"display(vw_predictions.limit(10).toPandas())"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"metrics = ComputeModelStatistics(\n",
							"    evaluationMetric='regression',\n",
							"    labelCol='target',\n",
							"    scoresCol='prediction'\n",
							").transform(vw_predictions)\n",
							"\n",
							"vw_result = metrics.toPandas()\n",
							"vw_result.insert(0, 'model', ['Vowpal Wabbit'])\n",
							"results = results.append(\n",
							"    vw_result,\n",
							"    ignore_index=True\n",
							")\n",
							"display(results)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"## LightGBM"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"lgr = LightGBMRegressor(\n",
							"    objective='quantile',\n",
							"    alpha=0.2,\n",
							"    learningRate=0.3,\n",
							"    numLeaves=31,\n",
							"    labelCol='target',\n",
							"    numIterations=100,\n",
							")\n",
							"\n",
							"# Using one partition since the training dataset is very small\n",
							"repartitioned_data = lr_train_data.repartition(1).cache()\n",
							"print(repartitioned_data.count())\n",
							"lg_model = lgr.fit(repartitioned_data)\n",
							"lg_predictions = lg_model.transform(lr_test_data)\n",
							"\n",
							"display(lg_predictions.limit(10).toPandas())"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"metrics = ComputeModelStatistics(\n",
							"    evaluationMetric='regression',\n",
							"    labelCol='target',\n",
							"    scoresCol='prediction'\n",
							").transform(lg_predictions)\n",
							"\n",
							"lg_result = metrics.toPandas()\n",
							"lg_result.insert(0, 'model', ['LightGBM'])\n",
							"results = results.append(\n",
							"    lg_result,\n",
							"    ignore_index=True\n",
							")\n",
							"display(results)"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"metadata": {},
						"source": [
							"Following figure shows the actual-vs.-prediction graphs of the results:\n",
							"\n",
							"<img width=\"1102\" alt=\"lr-vw-lg\" src=\"https://user-images.githubusercontent.com/42475935/64071975-4c3e9600-cc54-11e9-8b1f-9a1ee300f445.png\">"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"cmap = get_cmap('YlOrRd')\n",
							"\n",
							"target = np.array(test_data.select('target').collect()).flatten()\n",
							"model_preds = [\n",
							"    (\"Spark MLlib Linear Regression\", lr_predictions),\n",
							"    (\"Vowpal Wabbit\", vw_predictions),\n",
							"    (\"LightGBM\", lg_predictions)\n",
							"]"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": true
						},
						"source": [
							"f, axes = plt.subplots(1, len(model_preds), sharey=True, figsize=(18, 6))\r\n",
							"f.tight_layout()\r\n",
							"\r\n",
							"for i, (model_name, preds) in enumerate(model_preds):\r\n",
							"    preds = np.array(preds.select('prediction').collect()).flatten()\r\n",
							"    err = np.absolute(preds - target)\r\n",
							"\r\n",
							"    norm = Normalize()\r\n",
							"    clrs = cmap(np.asarray(norm(err)))[:, :-1]\r\n",
							"    axes[i].scatter(preds, target, s=60, c=clrs, edgecolors='#888888', alpha=0.75)\r\n",
							"    axes[i].plot((0, 60), (0, 60), linestyle='--', color='#888888')\r\n",
							"    axes[i].set_xlabel('Predicted values')\r\n",
							"    if i ==0:\r\n",
							"        axes[i].set_ylabel('Actual values')\r\n",
							"    axes[i].set_title(model_name)\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Clean up resources\r\n",
							"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
							"\r\n",
							"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Next steps\r\n",
							"\r\n",
							"* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
							"* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)"
						]
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/main')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sppgbdemo",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "bb3cfe25-d067-41d9-8e78-32c239078663"
					}
				},
				"metadata": {
					"saveOutput": true,
					"synapse_widget": {
						"version": "0.1",
						"state": {
							"ba48a810-b1d2-4d25-b569-073d349eec78": {
								"type": "Synapse.DataFrame",
								"sync_state": {
									"table": {
										"rows": [
											{
												"0": "first_name",
												"1": "last_name",
												"2": "company_name",
												"3": "address",
												"4": "city",
												"5": "county",
												"6": "state",
												"7": "zip",
												"8": "phone1",
												"9": "phone2",
												"10": "email",
												"11": "web"
											},
											{
												"0": "James",
												"1": "Butt",
												"2": "Benton, John B Jr",
												"3": "6649 N Blue Gum St",
												"4": "New Orleans",
												"5": "Orleans",
												"6": "LA",
												"7": "70116",
												"8": "504-621-8927",
												"9": "504-845-1427",
												"10": "jbutt@gmail.com",
												"11": "http://www.bentonjohnbjr.com"
											},
											{
												"0": "Josephine",
												"1": "Darakjy",
												"2": "Chanay, Jeffrey A Esq",
												"3": "4 B Blue Ridge Blvd",
												"4": "Brighton",
												"5": "Livingston",
												"6": "MI",
												"7": "48116",
												"8": "810-292-9388",
												"9": "810-374-9840",
												"10": "josephine_darakjy@darakjy.org",
												"11": "http://www.chanayjeffreyaesq.com"
											},
											{
												"0": "Art",
												"1": "Venere",
												"2": "Chemel, James L Cpa",
												"3": "8 W Cerritos Ave #54",
												"4": "Bridgeport",
												"5": "Gloucester",
												"6": "NJ",
												"7": "08014",
												"8": "856-636-8749",
												"9": "856-264-4130",
												"10": "art@venere.org",
												"11": "http://www.chemeljameslcpa.com"
											},
											{
												"0": "Lenna",
												"1": "Paprocki",
												"2": "Feltz Printing Service",
												"3": "639 Main St",
												"4": "Anchorage",
												"5": "Anchorage",
												"6": "AK",
												"7": "99501",
												"8": "907-385-4412",
												"9": "907-921-2010",
												"10": "lpaprocki@hotmail.com",
												"11": "http://www.feltzprintingservice.com"
											},
											{
												"0": "Donette",
												"1": "Foller",
												"2": "Printing Dimensions",
												"3": "34 Center St",
												"4": "Hamilton",
												"5": "Butler",
												"6": "OH",
												"7": "45011",
												"8": "513-570-1893",
												"9": "513-549-4561",
												"10": "donette.foller@cox.net",
												"11": "http://www.printingdimensions.com"
											},
											{
												"0": "Simona",
												"1": "Morasca",
												"2": "Chapman, Ross E Esq",
												"3": "3 Mcauley Dr",
												"4": "Ashland",
												"5": "Ashland",
												"6": "OH",
												"7": "44805",
												"8": "419-503-2484",
												"9": "419-800-6759",
												"10": "simona@morasca.com",
												"11": "http://www.chapmanrosseesq.com"
											},
											{
												"0": "Mitsue",
												"1": "Tollner",
												"2": "Morlong Associates",
												"3": "7 Eads St",
												"4": "Chicago",
												"5": "Cook",
												"6": "IL",
												"7": "60632",
												"8": "773-573-6914",
												"9": "773-924-8565",
												"10": "mitsue_tollner@yahoo.com",
												"11": "http://www.morlongassociates.com"
											},
											{
												"0": "Leota",
												"1": "Dilliard",
												"2": "Commercial Press",
												"3": "7 W Jackson Blvd",
												"4": "San Jose",
												"5": "Santa Clara",
												"6": "CA",
												"7": "95111",
												"8": "408-752-3500",
												"9": "408-813-1105",
												"10": "leota@hotmail.com",
												"11": "http://www.commercialpress.com"
											},
											{
												"0": "Sage",
												"1": "Wieser",
												"2": "Truhlar And Truhlar Attys",
												"3": "5 Boston Ave #88",
												"4": "Sioux Falls",
												"5": "Minnehaha",
												"6": "SD",
												"7": "57105",
												"8": "605-414-2147",
												"9": "605-794-4895",
												"10": "sage_wieser@cox.net",
												"11": "http://www.truhlarandtruhlarattys.com"
											}
										],
										"schema": [
											{
												"key": "0",
												"name": "_c0",
												"type": "string"
											},
											{
												"key": "1",
												"name": "_c1",
												"type": "string"
											},
											{
												"key": "2",
												"name": "_c2",
												"type": "string"
											},
											{
												"key": "3",
												"name": "_c3",
												"type": "string"
											},
											{
												"key": "4",
												"name": "_c4",
												"type": "string"
											},
											{
												"key": "5",
												"name": "_c5",
												"type": "string"
											},
											{
												"key": "6",
												"name": "_c6",
												"type": "string"
											},
											{
												"key": "7",
												"name": "_c7",
												"type": "string"
											},
											{
												"key": "8",
												"name": "_c8",
												"type": "string"
											},
											{
												"key": "9",
												"name": "_c9",
												"type": "string"
											},
											{
												"key": "10",
												"name": "_c10",
												"type": "string"
											},
											{
												"key": "11",
												"name": "_c11",
												"type": "string"
											}
										],
										"truncated": false
									},
									"isSummary": false,
									"language": "scala"
								},
								"persist_state": {
									"view": {
										"type": "details",
										"chartOptions": {
											"chartType": "bar",
											"aggregationType": "count",
											"categoryFieldKeys": [
												"0"
											],
											"seriesFieldKeys": [
												"0"
											],
											"isStacked": false
										}
									}
								}
							}
						}
					},
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a354618a-57e3-4180-ae87-3fed27f4297d/resourceGroups/rgpgbdemo/providers/Microsoft.Synapse/workspaces/synapsepgbdemo/bigDataPools/sppgbdemo",
						"name": "sppgbdemo",
						"type": "Spark",
						"endpoint": "https://synapsepgbdemo.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sppgbdemo",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://landing@sapgbdemo1.dfs.core.windows.net/cust_500.csv', format='csv'\r\n",
							"## If header exists uncomment line below\r\n",
							"##, header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"attachments": null,
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sppgbdemo')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		}
	]
}